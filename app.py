"""
ç«¶é¦¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  V4 - Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
ãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±ã®ã¿ã‚’ä½¿ç”¨ã—ãŸã‚¿ã‚¤ãƒ äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 

æ©Ÿèƒ½:
- CSVä¸€æ‹¬äºˆæ¸¬
- æ‰‹å‹•å…¥åŠ›äºˆæ¸¬  
- V4é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ï¼ˆMAE 0.961ç§’ï¼‰
- ãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±ã®ã¿ä½¿ç”¨ã§å®Ÿç”¨çš„
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
from pathlib import Path
import logging
from typing import Optional, Dict, Any, List, Tuple
import traceback
import unicodedata

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ‡ ç«¶é¦¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  V4",
    page_icon="ğŸ‡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BloodlineManager:
    """è¡€çµ±ãƒã‚¹ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, master_file_path: str):
        """è¡€çµ±ãƒã‚¹ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§åˆæœŸåŒ–"""
        self.master_file_path = Path(master_file_path)
        self.bloodline_dict = {}
        self.logger = logging.getLogger(__name__)
        self._load_bloodline_master()
    
    def _load_bloodline_master(self) -> None:
        """è¡€çµ±ãƒã‚¹ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€è¾æ›¸å½¢å¼ã§ä¿å­˜"""
        try:
            df = pd.read_csv(self.master_file_path, encoding='utf-8-sig')
            
            # å¿…è¦ãªåˆ—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            required_cols = ['é¦¬å', 'å°ç³»çµ±', 'å›½ç³»çµ±']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                raise ValueError(f"è¡€çµ±ãƒã‚¹ã‚¿ã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing_cols}")
            
            # è¡€çµ±è¾æ›¸ã‚’æ§‹ç¯‰
            for _, row in df.iterrows():
                horse_name = self.normalize_text(row['é¦¬å'])
                if horse_name:
                    self.bloodline_dict[horse_name] = (
                        row['å°ç³»çµ±'] if pd.notna(row['å°ç³»çµ±']) else 'UNKNOWN',
                        row['å›½ç³»çµ±'] if pd.notna(row['å›½ç³»çµ±']) else 'UNKNOWN'
                    )
            
            self.logger.info(f"è¡€çµ±ãƒã‚¹ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(self.bloodline_dict)}é ­ã®é¦¬")
            
        except Exception as e:
            self.logger.error(f"è¡€çµ±ãƒã‚¹ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            raise RuntimeError(f"è¡€çµ±ãƒã‚¹ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}") from e
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–"""
        if pd.isna(text):
            return ''
        return unicodedata.normalize('NFKC', str(text)).strip()
    
    def lookup_bloodline(self, horse_name: str) -> Tuple[str, str]:
        """é¦¬åã‹ã‚‰è¡€çµ±æƒ…å ±ã‚’æ¤œç´¢"""
        normalized_name = self.normalize_text(horse_name)
        
        if normalized_name in self.bloodline_dict:
            return self.bloodline_dict[normalized_name]
        else:
            self.logger.warning(f"è¡€çµ±æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {horse_name}")
            return ('UNKNOWN', 'UNKNOWN')
    
    def enrich_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """DataFrameã«è¡€çµ±æƒ…å ±ã‚’è¿½åŠ """
        result_df = df.copy()
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        found_count = 0
        not_found_horses = []
        
        # çˆ¶é¦¬åã¨æ¯ã®çˆ¶é¦¬åã®è¡€çµ±æƒ…å ±ã‚’è¿½åŠ 
        for horse_type, prefix in [('çˆ¶é¦¬å', 'çˆ¶'), ('æ¯ã®çˆ¶é¦¬å', 'æ¯çˆ¶')]:
            if horse_type not in result_df.columns:
                self.logger.warning(f"åˆ— '{horse_type}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            small_lineages = []
            country_lineages = []
            
            for horse_name in result_df[horse_type]:
                small, country = self.lookup_bloodline(horse_name)
                small_lineages.append(small)
                country_lineages.append(country)
                
                # ãƒ‡ãƒãƒƒã‚°: è¦‹ã¤ã‹ã£ãŸã‹ã‚«ã‚¦ãƒ³ãƒˆ
                if small != 'UNKNOWN' and country != 'UNKNOWN':
                    found_count += 1
                else:
                    not_found_horses.append(horse_name)
            
            result_df[f'{prefix}_å°ç³»çµ±'] = small_lineages
            result_df[f'{prefix}_å›½ç³»çµ±'] = country_lineages
        
        self.logger.info(f"è¡€çµ±æƒ…å ±ã‚’è¿½åŠ : æˆåŠŸ={found_count}ä»¶, æœªç™ºè¦‹={len(not_found_horses)}ä»¶")
        
        # æœªç™ºè¦‹ã®é¦¬ã‚’ãƒ­ã‚°å‡ºåŠ›
        if not_found_horses:
            self.logger.warning(f"è¡€çµ±ãƒã‚¹ã‚¿ã«è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸé¦¬: {set(not_found_horses)}")
        
        return result_df, not_found_horses  # æœªç™ºè¦‹ãƒªã‚¹ãƒˆã‚‚è¿”ã™

class KeibaV4PredictionApp:
    """V4ç«¶é¦¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self):
        self.model = None
        self.encoders = None
        self.feature_columns = None
        self.model_loaded = False
        self.bloodline_manager = None
        
        # è¡€çµ±ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼èª­ã¿è¾¼ã¿
        self.load_bloodline_manager()
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        self.load_v4_model()
    
    def load_bloodline_manager(self):
        """è¡€çµ±ãƒã‚¹ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            bloodline_paths = [
                Path("data/bloodline_master.csv"),
                Path("./data/bloodline_master.csv"),
                Path("../data/bloodline_master.csv")
            ]
            
            for bloodline_path in bloodline_paths:
                if bloodline_path.exists():
                    self.bloodline_manager = BloodlineManager(str(bloodline_path))
                    logger.info(f"è¡€çµ±ãƒã‚¹ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {bloodline_path}")
                    return
            
            logger.warning("âš ï¸ è¡€çµ±ãƒã‚¹ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¡€çµ±è£œå®Œæ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")
            
        except Exception as e:
            logger.error(f"è¡€çµ±ãƒã‚¹ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.warning("âš ï¸ è¡€çµ±ãƒã‚¹ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¡€çµ±è£œå®Œæ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")
    
    def load_v4_model(self):
        """V4ãƒ¢ãƒ‡ãƒ«ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # GitHub Codespaces/Streamlit Cloudç”¨ã®ãƒ‘ã‚¹èª¿æ•´
            model_paths = [
                # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨
                Path("ml_models_v4/models/lgb_v4_time_model_20251108_211745.pkl"),
                Path("../ml_models_v4/models/lgb_v4_time_model_20251108_211745.pkl"),
                # ãƒ‡ãƒ—ãƒ­ã‚¤ç”¨
                Path("models/lgb_v4_time_model.pkl"),
                Path("./models/lgb_v4_time_model.pkl")
            ]
            
            encoder_paths = [
                Path("ml_models_v4/models/label_encoders_v4_20251108_211745.pkl"),
                Path("../ml_models_v4/models/label_encoders_v4_20251108_211745.pkl"),
                Path("models/label_encoders_v4.pkl"),
                Path("./models/label_encoders_v4.pkl")
            ]
            
            feature_paths = [
                Path("ml_models_v4/models/feature_columns_v4_20251108_211745.json"),
                Path("../ml_models_v4/models/feature_columns_v4_20251108_211745.json"),
                Path("models/feature_columns_v4.json"),
                Path("./models/feature_columns_v4.json")
            ]
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            model_loaded = False
            for model_path in model_paths:
                if model_path.exists():
                    self.model = joblib.load(model_path)
                    model_loaded = True
                    logger.info(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {model_path}")
                    break
            
            if not model_loaded:
                st.error("âŒ V4ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿
            encoder_loaded = False
            for encoder_path in encoder_paths:
                if encoder_path.exists():
                    self.encoders = joblib.load(encoder_path)
                    encoder_loaded = True
                    logger.info(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿æˆåŠŸ: {encoder_path}")
                    break
            
            if not encoder_loaded:
                st.error("âŒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿
            features_loaded = False
            for feature_path in feature_paths:
                if feature_path.exists():
                    with open(feature_path, 'r', encoding='utf-8') as f:
                        self.feature_columns = json.load(f)
                    features_loaded = True
                    logger.info(f"ç‰¹å¾´é‡ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿æˆåŠŸ: {feature_path}")
                    break
            
            if not features_loaded:
                st.error("âŒ ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            self.model_loaded = True
            st.success("âœ… V4ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            
        except Exception as e:
            st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
    
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """V4ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"""
        try:
            df = df.copy()
            
            # 0. è¡€çµ±æƒ…å ±ã®æ¬ æå€¤ã‚’UNKNOWNã«ç½®ãæ›ãˆ
            bloodline_cols = ['çˆ¶_å°ç³»çµ±', 'çˆ¶_å›½ç³»çµ±', 'æ¯çˆ¶_å°ç³»çµ±', 'æ¯çˆ¶_å›½ç³»çµ±']
            for col in bloodline_cols:
                if col in df.columns:
                    df[col] = df[col].fillna('UNKNOWN').replace('', 'UNKNOWN')
            
            # 1. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            categorical_cols = [
                'å ´æ‰€', 'èŠãƒ»ãƒ€', 'é¦¬å ´çŠ¶æ…‹', 'æ€§åˆ¥', 'é¨æ‰‹å', 'èª¿æ•™å¸«',
                'çˆ¶_å°ç³»çµ±', 'çˆ¶_å›½ç³»çµ±', 'æ¯çˆ¶_å°ç³»çµ±', 'æ¯çˆ¶_å›½ç³»çµ±'
            ]
            
            for col in categorical_cols:
                if col in df.columns and col in self.encoders:
                    df[f'{col}_encoded'] = df[col].astype(str).apply(
                        lambda x: self.encoders[col].transform([x])[0] 
                        if x in self.encoders[col].classes_ else 0
                    )
            
            # 2. æ•°å€¤ç‰¹å¾´é‡ã®å¤‰æ›
            if 'å˜å‹ã‚ªãƒƒã‚º' in df.columns:
                df['å˜å‹ã‚ªãƒƒã‚º_log'] = np.log1p(df['å˜å‹ã‚ªãƒƒã‚º'].fillna(df['å˜å‹ã‚ªãƒƒã‚º'].median()))
            
            # 3. æ—¥ä»˜ç‰¹å¾´é‡
            if all(col in df.columns for col in ['å¹´', 'æœˆ']):
                df['å¹´æœˆ'] = df['å¹´'] * 100 + df['æœˆ']
                df['å­£ç¯€'] = df['æœˆ'].apply(self._get_season)
            
            # 4. çµ„ã¿åˆã‚ã›ç‰¹å¾´é‡
            if all(col in df.columns for col in ['è·é›¢', 'èŠãƒ»ãƒ€']):
                df['è·é›¢_è¡¨é¢'] = df['è·é›¢'].astype(str) + '_' + df['èŠãƒ»ãƒ€'].astype(str)
                if 'è·é›¢_è¡¨é¢' in self.encoders:
                    df['è·é›¢_è¡¨é¢_encoded'] = df['è·é›¢_è¡¨é¢'].apply(
                        lambda x: self.encoders['è·é›¢_è¡¨é¢'].transform([x])[0] 
                        if x in self.encoders['è·é›¢_è¡¨é¢'].classes_ else 0
                    )
            
            # 5. è¡€çµ±çµ„ã¿åˆã‚ã›
            if all(col in df.columns for col in ['çˆ¶_å°ç³»çµ±', 'æ¯çˆ¶_å°ç³»çµ±']):
                df['è¡€çµ±çµ„ã¿åˆã‚ã›'] = df['çˆ¶_å°ç³»çµ±'].astype(str) + '_' + df['æ¯çˆ¶_å°ç³»çµ±'].astype(str)
                if 'è¡€çµ±çµ„ã¿åˆã‚ã›' in self.encoders:
                    df['è¡€çµ±çµ„ã¿åˆã‚ã›_encoded'] = df['è¡€çµ±çµ„ã¿åˆã‚ã›'].apply(
                        lambda x: self.encoders['è¡€çµ±çµ„ã¿åˆã‚ã›'].transform([x])[0] 
                        if x in self.encoders['è¡€çµ±çµ„ã¿åˆã‚ã›'].classes_ else 0
                    )
            
            return df
            
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(f"å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return df
    
    def _get_season(self, month: int) -> int:
        """æœˆã‹ã‚‰å­£ç¯€ã‚’å–å¾—"""
        if month in [12, 1, 2]:
            return 0  # å†¬
        elif month in [3, 4, 5]:
            return 1  # æ˜¥
        elif month in [6, 7, 8]:
            return 2  # å¤
        else:
            return 3  # ç§‹
    
    def predict_race_time(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """ãƒ¬ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ äºˆæ¸¬"""
        if not self.model_loaded:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        try:
            # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            processed_df = self.preprocess_data(df)
            
            # å¿…è¦ãªç‰¹å¾´é‡ã®ç¢ºèª
            available_features = [col for col in self.feature_columns if col in processed_df.columns]
            missing_features = [col for col in self.feature_columns if col not in processed_df.columns]
            
            if missing_features:
                st.warning(f"âš ï¸ ä¸è¶³ç‰¹å¾´é‡: {missing_features}")
            
            # äºˆæ¸¬å®Ÿè¡Œ
            X = processed_df[available_features].copy()
            X = X.fillna(X.median())  # æ¬ æå€¤å‡¦ç†
            
            predicted_times = self.model.predict(X)
            
            # çµæœã‚’DataFrameã«è¿½åŠ 
            result_df = df.copy()
            result_df['äºˆæ¸¬ã‚¿ã‚¤ãƒ '] = predicted_times
            result_df['äºˆæ¸¬é †ä½'] = result_df['äºˆæ¸¬ã‚¿ã‚¤ãƒ '].rank(method='min')
            
            return result_df
            
        except Exception as e:
            st.error(f"âŒ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return None
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        st.title("ğŸ‡ ç«¶é¦¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  V4")
        st.markdown("### ãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±ã«ã‚ˆã‚‹é«˜ç²¾åº¦ã‚¿ã‚¤ãƒ äºˆæ¸¬")
        
        if not self.model_loaded:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
            return
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼æƒ…å ±
        st.sidebar.markdown("## ğŸ“Š V4ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        st.sidebar.markdown("""
        **äºˆæ¸¬ç²¾åº¦ï¼ˆ2025å¹´å®Ÿæ¸¬ï¼‰:**
        - MAE: 0.961ç§’
        - RMSE: 1.841ç§’  
        - ç²¾åº¦: 90.6% (2ç§’ä»¥å†…)
        
        **ä½¿ç”¨ç‰¹å¾´é‡:**
        - åŸºæœ¬ãƒ¬ãƒ¼ã‚¹æ¡ä»¶
        - é¦¬ãƒ»é¨æ‰‹ãƒ»èª¿æ•™å¸«æƒ…å ±
        - è¡€çµ±ç³»çµ±æƒ…å ±
        - äººæ°—ãƒ»ã‚ªãƒƒã‚ºæƒ…å ±
        
        **ç‰¹å¾´:**
        - âœ… ãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±ã®ã¿ä½¿ç”¨
        - âœ… å®Ÿç”¨çš„ãªäºˆæ¸¬ç²¾åº¦
        - âœ… ã‚¿ã‚¤ãƒ â†’é †ä½å¤‰æ›
        """)
        
        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        tab1, tab2, tab3 = st.tabs(["ğŸ“ CSVä¸€æ‹¬äºˆæ¸¬", "âœï¸ æ‰‹å‹•å…¥åŠ›", "ğŸ“š ä½¿ã„æ–¹"])
        
        with tab1:
            self.csv_prediction_interface()
        
        with tab2:
            self.manual_input_interface()
        
        with tab3:
            self.usage_guide()
    
    def csv_prediction_interface(self):
        """CSVä¸€æ‹¬äºˆæ¸¬ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        st.markdown("## ğŸ“ CSVä¸€æ‹¬äºˆæ¸¬")
        st.markdown("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¸€æ‹¬äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        
        # CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¬æ˜
        with st.expander("ğŸ“‹ å¿…è¦ãªCSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"):
            st.markdown("""
            ### å¿…é ˆã‚«ãƒ©ãƒ :
            - **åŸºæœ¬æƒ…å ±**: `è·é›¢`, `é ­æ•°`, `é¦¬ç•ª`, `å¹´é½¢`, `æ–¤é‡`
            - **ãƒ¬ãƒ¼ã‚¹æ¡ä»¶**: `å ´æ‰€`, `èŠãƒ»ãƒ€`, `é¦¬å ´çŠ¶æ…‹`
            - **äººé–“æƒ…å ±**: `é¨æ‰‹å`, `èª¿æ•™å¸«`, `æ€§åˆ¥`
            - **äººæ°—æƒ…å ±**: `äººæ°—é †`, `å˜å‹ã‚ªãƒƒã‚º`
            - **æ—¥ä»˜æƒ…å ±**: `å¹´`, `æœˆ`, `æ—¥`
            - **è­˜åˆ¥æƒ…å ±**: `é¦¬å`
            
            ### è¡€çµ±æƒ…å ±ï¼ˆä»¥ä¸‹ã®ã„ãšã‚Œã‹ï¼‰:
            
            **ãƒ‘ã‚¿ãƒ¼ãƒ³1: è¡€çµ±ç³»çµ±ã‚’ç›´æ¥æŒ‡å®š**
            - `çˆ¶_å°ç³»çµ±`, `çˆ¶_å›½ç³»çµ±`, `æ¯çˆ¶_å°ç³»çµ±`, `æ¯çˆ¶_å›½ç³»çµ±`
            
            **ãƒ‘ã‚¿ãƒ¼ãƒ³2: é¦¬åã‹ã‚‰è‡ªå‹•è£œå®Œï¼ˆæ¨å¥¨ï¼‰**
            - `çˆ¶é¦¬å`, `æ¯ã®çˆ¶é¦¬å` â†’ ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•çš„ã«ç³»çµ±æƒ…å ±ã‚’è£œå®Œã—ã¾ã™
            
            ### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³1ï¼‰:
            ```csv
            é¦¬å,å¹´,æœˆ,æ—¥,å ´æ‰€,èŠãƒ»ãƒ€,è·é›¢,é¦¬å ´çŠ¶æ…‹,é¦¬ç•ª,æ€§åˆ¥,å¹´é½¢,é¨æ‰‹å,èª¿æ•™å¸«,æ–¤é‡,é ­æ•°,äººæ°—é †,å˜å‹ã‚ªãƒƒã‚º,çˆ¶_å°ç³»çµ±,çˆ¶_å›½ç³»çµ±,æ¯çˆ¶_å°ç³»çµ±,æ¯çˆ¶_å›½ç³»çµ±
            ã‚µãƒ³ãƒ—ãƒ«é¦¬,25,11,10,æ±äº¬,èŠ,2000,è‰¯,1,ç‰¡,4,é¨æ‰‹A,èª¿æ•™å¸«B,57,16,1,2.1,ãƒ‡ã‚£ãƒ¼ãƒ—ç³»,æ—¥æœ¬å‹ã‚µãƒ³ãƒ‡ãƒ¼ç³»,ã‚­ãƒ³ã‚°ãƒãƒ³ãƒœç³»,æ¬§å·å‹ãƒŸã‚¹ãƒ—ãƒ­ç³»
            ```
            
            ### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³2 - è‡ªå‹•è£œå®Œï¼‰:
            ```csv
            é¦¬å,å¹´,æœˆ,æ—¥,å ´æ‰€,èŠãƒ»ãƒ€,è·é›¢,é¦¬å ´çŠ¶æ…‹,é¦¬ç•ª,æ€§åˆ¥,å¹´é½¢,é¨æ‰‹å,èª¿æ•™å¸«,æ–¤é‡,é ­æ•°,äººæ°—é †,å˜å‹ã‚ªãƒƒã‚º,çˆ¶é¦¬å,æ¯ã®çˆ¶é¦¬å
            ã‚µãƒ³ãƒ—ãƒ«é¦¬,25,11,10,æ±äº¬,èŠ,2000,è‰¯,1,ç‰¡,4,é¨æ‰‹A,èª¿æ•™å¸«B,57,16,1,2.1,ãƒ‡ã‚£ãƒ¼ãƒ—ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ,ã‚­ãƒ³ã‚°ãƒãƒ³ãƒœ
            ```
            
            â€» ãƒ‘ã‚¿ãƒ¼ãƒ³2ã®å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•çš„ã«è¡€çµ±ç³»çµ±æƒ…å ±ã‚’ä»˜ä¸ã—ã¾ã™
            """)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_file = st.file_uploader(
            "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=['csv'],
            help="ä¸Šè¨˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã£ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file is not None:
            try:
                # CSVèª­ã¿è¾¼ã¿
                df = pd.read_csv(uploaded_file, encoding='utf-8')
                st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                st.markdown("### ğŸ“Š ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(df.head(10), use_container_width=True)
                
                # è¡€çµ±æƒ…å ±ã®è‡ªå‹•è£œå®Œãƒã‚§ãƒƒã‚¯
                bloodline_cols = ['çˆ¶_å°ç³»çµ±', 'çˆ¶_å›½ç³»çµ±', 'æ¯çˆ¶_å°ç³»çµ±', 'æ¯çˆ¶_å›½ç³»çµ±']
                missing_bloodline = [col for col in bloodline_cols if col not in df.columns]
                
                if missing_bloodline and self.bloodline_manager:
                    # çˆ¶é¦¬åã¨æ¯ã®çˆ¶é¦¬åãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if 'çˆ¶é¦¬å' in df.columns and 'æ¯ã®çˆ¶é¦¬å' in df.columns:
                        st.info("ğŸ§¬ è¡€çµ±æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚çˆ¶é¦¬åãƒ»æ¯ã®çˆ¶é¦¬åã‹ã‚‰è‡ªå‹•è£œå®Œã—ã¾ã™...")
                        
                        with st.spinner("è¡€çµ±æƒ…å ±ã‚’è£œå®Œä¸­..."):
                            df, not_found_horses = self.bloodline_manager.enrich_dataframe(df)
                        
                        st.success("âœ… è¡€çµ±æƒ…å ±ã‚’è£œå®Œã—ã¾ã—ãŸ")
                        
                        # è£œå®Œçµ±è¨ˆæƒ…å ±
                        total_horses = len(df) * 2  # çˆ¶ + æ¯çˆ¶
                        found_count = total_horses - len(not_found_horses)
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ç·é¦¬æ•°", f"{total_horses}é ­")
                        with col2:
                            st.metric("è£œå®ŒæˆåŠŸ", f"{found_count}é ­", delta=f"{found_count/total_horses*100:.1f}%")
                        with col3:
                            st.metric("æœªç™ºè¦‹", f"{len(not_found_horses)}é ­")
                        
                        # æœªç™ºè¦‹ã®é¦¬ãƒªã‚¹ãƒˆè¡¨ç¤º
                        if not_found_horses:
                            with st.expander("âš ï¸ è¡€çµ±ãƒã‚¹ã‚¿ã«è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸé¦¬ï¼ˆUNKNOWNè¨­å®šï¼‰"):
                                unique_not_found = sorted(set(not_found_horses))
                                st.write(", ".join(unique_not_found))
                        
                        # è£œå®Œçµæœã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                        st.markdown("#### ğŸ“‹ è£œå®Œå¾Œãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå…ˆé ­5è¡Œï¼‰")
                        sample_cols = ['é¦¬å', 'çˆ¶é¦¬å', 'çˆ¶_å°ç³»çµ±', 'çˆ¶_å›½ç³»çµ±', 'æ¯ã®çˆ¶é¦¬å', 'æ¯çˆ¶_å°ç³»çµ±', 'æ¯çˆ¶_å›½ç³»çµ±']
                        st.dataframe(df[sample_cols].head(5), use_container_width=True)
                        
                        # è£œå®Œå¾Œã®å…¨ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                        with st.expander("ğŸ“Š è£œå®Œå¾Œã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
                            st.dataframe(df, use_container_width=True, height=400)
                    else:
                        st.error("âŒ è¡€çµ±æƒ…å ±ã®è£œå®Œã«ã¯ `çˆ¶é¦¬å` ã¨ `æ¯ã®çˆ¶é¦¬å` ã®åˆ—ãŒå¿…è¦ã§ã™")
                        st.stop()
                
                # å¿…è¦ã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯
                required_cols = [
                    'é¦¬å', 'å¹´', 'æœˆ', 'æ—¥', 'å ´æ‰€', 'èŠãƒ»ãƒ€', 'è·é›¢', 'é¦¬å ´çŠ¶æ…‹',
                    'é¦¬ç•ª', 'æ€§åˆ¥', 'å¹´é½¢', 'é¨æ‰‹å', 'èª¿æ•™å¸«', 'æ–¤é‡', 'é ­æ•°',
                    'äººæ°—é †', 'å˜å‹ã‚ªãƒƒã‚º', 'çˆ¶_å°ç³»çµ±', 'çˆ¶_å›½ç³»çµ±', 'æ¯çˆ¶_å°ç³»çµ±', 'æ¯çˆ¶_å›½ç³»çµ±'
                ]
                
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    st.error(f"âŒ ä¸è¶³ã‚«ãƒ©ãƒ : {missing_cols}")
                    st.stop()
                
                # äºˆæ¸¬å®Ÿè¡Œ
                if st.button("ğŸš€ äºˆæ¸¬å®Ÿè¡Œ", type="primary"):
                    with st.spinner("äºˆæ¸¬ä¸­..."):
                        result_df = self.predict_race_time(df)
                    
                    if result_df is not None:
                        st.markdown("### ğŸ¯ äºˆæ¸¬çµæœ")
                        
                        # çµæœè¡¨ç¤º
                        display_cols = ['é¦¬å', 'äºˆæ¸¬ã‚¿ã‚¤ãƒ ', 'äºˆæ¸¬é †ä½', 'äººæ°—é †', 'å˜å‹ã‚ªãƒƒã‚º']
                        st.dataframe(
                            result_df[display_cols].sort_values('äºˆæ¸¬é †ä½'),
                            use_container_width=True
                        )
                        
                        # çµ±è¨ˆæƒ…å ±
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æœ€é€Ÿäºˆæƒ³", f"{result_df['äºˆæ¸¬ã‚¿ã‚¤ãƒ '].min():.1f}ç§’")
                        with col2:
                            st.metric("æœ€é…äºˆæƒ³", f"{result_df['äºˆæ¸¬ã‚¿ã‚¤ãƒ '].max():.1f}ç§’")
                        with col3:
                            st.metric("ã‚¿ã‚¤ãƒ å¹…", f"{result_df['äºˆæ¸¬ã‚¿ã‚¤ãƒ '].max() - result_df['äºˆæ¸¬ã‚¿ã‚¤ãƒ '].min():.1f}ç§’")
                        
                        # CSVä¸‹è½½
                        csv = result_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            "ğŸ“¥ çµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=csv,
                            file_name=f"keiba_prediction_v4_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                        
            except Exception as e:
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def manual_input_interface(self):
        """æ‰‹å‹•å…¥åŠ›ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        st.markdown("## âœï¸ æ‰‹å‹•å…¥åŠ›äºˆæ¸¬")
        st.markdown("1é ­ãšã¤è©³ç´°ã«å…¥åŠ›ã—ã¦äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        
        with st.form("manual_input_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### åŸºæœ¬æƒ…å ±")
                horse_name = st.text_input("é¦¬å", value="ã‚µãƒ³ãƒ—ãƒ«é¦¬")
                year = st.number_input("å¹´", min_value=20, max_value=30, value=25)
                month = st.number_input("æœˆ", min_value=1, max_value=12, value=11)
                day = st.number_input("æ—¥", min_value=1, max_value=31, value=10)
                
                st.markdown("### ãƒ¬ãƒ¼ã‚¹æ¡ä»¶")
                location = st.selectbox("ç«¶é¦¬å ´", ["æ±äº¬", "ä¸­å±±", "é˜ªç¥", "äº¬éƒ½", "æ–°æ½Ÿ", "å°å€‰", "å‡½é¤¨", "æœ­å¹Œ", "ä¸­äº¬", "ç¦å³¶"])
                surface = st.selectbox("èŠãƒ»ãƒ€ãƒ¼ãƒˆ", ["èŠ", "ãƒ€"])
                distance = st.number_input("è·é›¢(m)", min_value=1000, max_value=4000, value=2000, step=100)
                track_condition = st.selectbox("é¦¬å ´çŠ¶æ…‹", ["è‰¯", "ç¨é‡", "é‡", "ä¸è‰¯"])
                
            with col2:
                st.markdown("### é¦¬æƒ…å ±")
                horse_number = st.number_input("é¦¬ç•ª", min_value=1, max_value=18, value=1)
                gender = st.selectbox("æ€§åˆ¥", ["ç‰¡", "ç‰", "ã‚»"])
                age = st.number_input("å¹´é½¢", min_value=2, max_value=10, value=4)
                weight = st.number_input("æ–¤é‡", min_value=48.0, max_value=65.0, value=57.0, step=0.5)
                field_size = st.number_input("é ­æ•°", min_value=5, max_value=18, value=16)
                
                st.markdown("### äººæ°—ãƒ»ã‚ªãƒƒã‚º")
                popularity = st.number_input("äººæ°—é †", min_value=1, max_value=18, value=1)
                odds = st.number_input("å˜å‹ã‚ªãƒƒã‚º", min_value=1.0, max_value=999.9, value=2.1, step=0.1)
            
            col3, col4 = st.columns(2)
            with col3:
                st.markdown("### äººçš„è¦å› ")
                jockey = st.text_input("é¨æ‰‹å", value="é¨æ‰‹A")
                trainer = st.text_input("èª¿æ•™å¸«", value="èª¿æ•™å¸«B")
                
            with col4:
                st.markdown("### è¡€çµ±æƒ…å ±")
                father_small = st.selectbox("çˆ¶_å°ç³»çµ±", [
                    "ãƒ‡ã‚£ãƒ¼ãƒ—ç³»", "ã‚­ãƒ³ã‚°ãƒãƒ³ãƒœç³»", "Tã‚µãƒ³ãƒ‡ãƒ¼ç³»", "ãƒ­ãƒ™ãƒ«ãƒˆç³»", 
                    "Pã‚µãƒ³ãƒ‡ãƒ¼ç³»", "ã‚¹ãƒˆãƒ¼ãƒ ãƒãƒ¼ãƒ‰ç³»", "ãƒŸã‚¹ãƒ—ãƒ­ç³»", "ãã®ä»–"
                ])
                father_large = st.selectbox("çˆ¶_å›½ç³»çµ±", [
                    "æ—¥æœ¬å‹ã‚µãƒ³ãƒ‡ãƒ¼ç³»", "æ¬§å·å‹ãƒŸã‚¹ãƒ—ãƒ­ç³»", "ç±³å›½å‹ãƒãƒ¼ã‚¶ãƒ³ãƒ€ãƒ³ã‚µãƒ¼ç³»",
                    "æ¬§å·å‹ãƒãƒ¼ã‚¶ãƒ³ãƒ€ãƒ³ã‚µãƒ¼ç³»", "ç±³å›½å‹ãƒŸã‚¹ãƒ—ãƒ­ç³»", "ãã®ä»–"
                ])
                mother_small = st.selectbox("æ¯çˆ¶_å°ç³»çµ±", [
                    "ã‚­ãƒ³ã‚°ãƒãƒ³ãƒœç³»", "ãƒ‡ã‚£ãƒ¼ãƒ—ç³»", "Tã‚µãƒ³ãƒ‡ãƒ¼ç³»", "ãƒŸã‚¹ãƒ—ãƒ­ç³»",
                    "Pã‚µãƒ³ãƒ‡ãƒ¼ç³»", "ãƒ­ãƒ™ãƒ«ãƒˆç³»", "ãã®ä»–"
                ])
                mother_large = st.selectbox("æ¯çˆ¶_å›½ç³»çµ±", [
                    "æ¬§å·å‹ãƒŸã‚¹ãƒ—ãƒ­ç³»", "æ—¥æœ¬å‹ã‚µãƒ³ãƒ‡ãƒ¼ç³»", "ç±³å›½å‹ãƒãƒ¼ã‚¶ãƒ³ãƒ€ãƒ³ã‚µãƒ¼ç³»",
                    "æ¬§å·å‹ãƒãƒ¼ã‚¶ãƒ³ãƒ€ãƒ³ã‚µãƒ¼ç³»", "ç±³å›½å‹ãƒŸã‚¹ãƒ—ãƒ­ç³»", "ãã®ä»–"
                ])
            
            submitted = st.form_submit_button("ğŸ¯ äºˆæ¸¬å®Ÿè¡Œ", type="primary")
            
            if submitted:
                # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
                input_data = {
                    'é¦¬å': [horse_name],
                    'å¹´': [year], 'æœˆ': [month], 'æ—¥': [day],
                    'å ´æ‰€': [location], 'èŠãƒ»ãƒ€': [surface], 'è·é›¢': [distance], 'é¦¬å ´çŠ¶æ…‹': [track_condition],
                    'é¦¬ç•ª': [horse_number], 'æ€§åˆ¥': [gender], 'å¹´é½¢': [age], 'æ–¤é‡': [weight], 'é ­æ•°': [field_size],
                    'é¨æ‰‹å': [jockey], 'èª¿æ•™å¸«': [trainer],
                    'äººæ°—é †': [popularity], 'å˜å‹ã‚ªãƒƒã‚º': [odds],
                    'çˆ¶_å°ç³»çµ±': [father_small], 'çˆ¶_å›½ç³»çµ±': [father_large],
                    'æ¯çˆ¶_å°ç³»çµ±': [mother_small], 'æ¯çˆ¶_å›½ç³»çµ±': [mother_large]
                }
                
                df = pd.DataFrame(input_data)
                
                with st.spinner("äºˆæ¸¬ä¸­..."):
                    result_df = self.predict_race_time(df)
                
                if result_df is not None:
                    predicted_time = result_df['äºˆæ¸¬ã‚¿ã‚¤ãƒ '].iloc[0]
                    
                    st.markdown("### ğŸ¯ äºˆæ¸¬çµæœ")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("äºˆæ¸¬ã‚¿ã‚¤ãƒ ", f"{predicted_time:.2f}ç§’")
                    with col2:
                        st.metric("è·é›¢", f"{distance}m")
                    with col3:
                        st.metric("ãƒšãƒ¼ã‚¹", f"{predicted_time/distance*1000:.1f}ç§’/km")
                    
                    # è©³ç´°æƒ…å ±
                    st.markdown("### ğŸ“Š è©³ç´°æƒ…å ±")
                    info_df = pd.DataFrame({
                        'é …ç›®': ['é¦¬å', 'ç«¶é¦¬å ´', 'è·é›¢', 'é¦¬å ´', 'é¨æ‰‹', 'äººæ°—', 'ã‚ªãƒƒã‚º', 'äºˆæ¸¬ã‚¿ã‚¤ãƒ '],
                        'å€¤': [horse_name, location, f"{distance}m", track_condition, 
                              jockey, f"{popularity}ç•ªäººæ°—", f"{odds}å€", f"{predicted_time:.2f}ç§’"]
                    })
                    st.dataframe(info_df, use_container_width=True)
    
    def usage_guide(self):
        """ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰"""
        st.markdown("## ğŸ“š ç«¶é¦¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  V4 ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰")
        
        st.markdown("""
        ### ğŸ¯ V4ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´
        
        **é«˜ç²¾åº¦äºˆæ¸¬**:
        - 2025å¹´å®Ÿæ¸¬ã§å¹³å‡èª¤å·®0.961ç§’ã‚’é”æˆ
        - 90.6%ã®é¦¬ãŒ2ç§’ä»¥å†…ã®ç²¾åº¦ã§äºˆæ¸¬
        - ãƒ—ãƒ­äºˆæƒ³å®¶ãƒ¬ãƒ™ãƒ«ã®é †ä½äºˆæ¸¬ç²¾åº¦
        
        **å®Ÿç”¨æ€§**:
        - ãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±ã®ã¿ä½¿ç”¨ã§å®Ÿéš›ã«äºˆæ¸¬å¯èƒ½
        - ã‚¿ã‚¤ãƒ äºˆæ¸¬â†’é †ä½å¤‰æ›ã§å®‰å®šã—ãŸçµæœ
        - è¡€çµ±ãƒ»é¨æ‰‹ãƒ»äººæ°—æƒ…å ±ã‚’ç·åˆçš„ã«è©•ä¾¡
        
        ### ğŸ“ CSVä¸€æ‹¬äºˆæ¸¬ã®ä½¿ã„æ–¹
        
        1. **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæº–å‚™**: å¿…è¦ãª21é …ç›®ã‚’å«ã‚€CSVã‚’æº–å‚™
        2. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—
        3. **ãƒ‡ãƒ¼ã‚¿ç¢ºèª**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        4. **äºˆæ¸¬å®Ÿè¡Œ**: ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å…¨é ­ä¸€æ‹¬äºˆæ¸¬
        5. **çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: äºˆæ¸¬çµæœã‚’CSVã§å–å¾—
        
        ### âœï¸ æ‰‹å‹•å…¥åŠ›ã®ä½¿ã„æ–¹
        
        1. **åŸºæœ¬æƒ…å ±**: é¦¬åã€æ—¥ä»˜ã€ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ã‚’å…¥åŠ›
        2. **é¦¬æƒ…å ±**: é¦¬ç•ªã€å¹´é½¢ã€æ–¤é‡ãªã©ã®è©³ç´°
        3. **äººçš„è¦å› **: é¨æ‰‹ã€èª¿æ•™å¸«æƒ…å ±
        4. **è¡€çµ±æƒ…å ±**: çˆ¶ãƒ»æ¯çˆ¶ã®ç³»çµ±åˆ†é¡
        5. **äºˆæ¸¬å®Ÿè¡Œ**: å³åº§ã«ã‚¿ã‚¤ãƒ äºˆæ¸¬çµæœã‚’è¡¨ç¤º
        
        ### ğŸ² äºˆæ¸¬çµæœã®æ´»ç”¨æ³•
        
        **å˜å‹æˆ¦ç•¥**:
        - äºˆæ¸¬1ä½ã®é¦¬ã¸ã®æŠ•è³‡
        - äººæ°—è–„ã§äºˆæ¸¬ä¸Šä½ã®é¦¬ã‚’ç‹™ã„æ’ƒã¡
        
        **è¤‡å‹æˆ¦ç•¥**:
        - äºˆæ¸¬Top3ã¸ã®åˆ†æ•£æŠ•è³‡
        - é«˜ã„çš„ä¸­ç‡ã§å®‰å®šåç›Š
        
        **ç©´é¦¬ç™ºè¦‹**:
        - äººæ°—é † vs äºˆæ¸¬é †ä½ã®ä¹–é›¢ã‚’ãƒã‚§ãƒƒã‚¯
        - äººæ°—è–„Ã—äºˆæ¸¬ä¸Šä½ = é«˜é…å½“å€™è£œ
        
        ### âš ï¸ æ³¨æ„äº‹é …
        
        - äºˆæ¸¬ã¯çµ±è¨ˆçš„æ‰‹æ³•ã«åŸºã¥ãæ¨å®šå€¤ã§ã™
        - ç«¶é¦¬ã«ã¯ä¸ç¢ºå®šè¦ç´ ãŒå¤šãå«ã¾ã‚Œã¾ã™  
        - æŠ•è³‡ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„
        - ã‚·ã‚¹ãƒ†ãƒ ã®çµæœã‚’éä¿¡ã›ãšã€ç·åˆçš„ã«åˆ¤æ–­ã—ã¦ãã ã•ã„
        
        ### ğŸ“ ã‚µãƒãƒ¼ãƒˆæƒ…å ±
        
        - GitHub: https://github.com/Yu10Kumura/keiba-prediction-app
        - ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³: V4 (2025å¹´11æœˆç‰ˆ)
        - æœ€çµ‚æ›´æ–°: 2025å¹´11æœˆ8æ—¥
        """)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        app = KeibaV4PredictionApp()
        app.run()
    except Exception as e:
        st.error(f"âŒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        logger.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")

if __name__ == "__main__":
    main()